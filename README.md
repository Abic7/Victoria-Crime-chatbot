# ğŸ” Local RAG Assistant â€” Offline CSV Q&A with Gradio + Local LLMs

> Ask natural questions about your CSV data using semantic search and a local large language model. 100% offline. No OpenAI keys. No cloud dependencies.

![Gradio Screenshot](<img width="1088" height="981" alt="image" src="https://github.com/user-attachments/assets/25d7ab06-8905-492c-bd0e-46651141c46e" />) <!-- Replace with actual screenshot if available -->

---

## âœ¨ Overview

This project is a lightweight, offline-first **Retrieval-Augmented Generation (RAG)** system built with:

- ğŸ§  **Sentence Transformers** for semantic embeddings  
- âš¡ **FAISS** for high-speed vector search  
- ğŸ¤– **Local LLMs** via [LM Studio](https://lmstudio.ai/) or [Ollama](https://ollama.com)  
- ğŸ›ï¸ **Gradio** for an intuitive, browser-based UI

**Upload your CSV â†’ Ask a question â†’ Get a grounded, explainable answer.**

---

## ğŸ”§ Key Features

âœ… Upload any CSV (e.g., crime reports, transactions, logs)  
ğŸ” Ask natural language questions  
ğŸ“„ Retrieve semantically relevant rows using FAISS  
ğŸ§ª Auto-generate a structured, context-aware prompt  
ğŸ¤– Get an answer from a **local LLM**  
ğŸ” 100% offline â€” No internet or cloud APIs  
ğŸ“Š Full transparency: shows answer, context used, and raw prompt

---

## ğŸ“¦ Tech Stack

| Component        | Tool/Library                     |
|------------------|----------------------------------|
| UI               | [Gradio](https://www.gradio.app/)  
| Embeddings       | [SentenceTransformers](https://www.sbert.net/) (`all-MiniLM-L6-v2`)  
| Vector Search    | [FAISS](https://github.com/facebookresearch/faiss)  
| LLM Backend      | [LM Studio](https://lmstudio.ai/) or [Ollama](https://ollama.com)  
| Programming Lang | Python ğŸ  

---

## ğŸš€ Getting Started

### 1. Clone this repo

```bash
git clone https://github.com/yourusername/local-rag-assistant.git
cd local-rag-assistant
````

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

<details>
<summary>Requirements</summary>

```text
pandas
numpy
faiss-cpu
sentence-transformers
requests
gradio
```

</details>

---

### 3. Start your LLM locally

You can use any LLM served via OpenAI-compatible API. Recommended:

* ğŸ”¥ [LM Studio](https://lmstudio.ai/) â€“ supports many Hugging Face models

> Example local endpoint: `http://localhost:1234/v1/chat/completions`

---

### 4. Launch the Gradio app

```bash
python gradio_rag_app.py
```

Then open your browser to `http://localhost:7860`

---

## ğŸ§ª Example Questions (Crime Dataset)

```text
"What is the most stolen item in Abbotsford in 2025?"

"How many food-related items were stolen in postcode 3067?"

"List total value of items stolen in commercial zones in Q1 2025."
```

---

## ğŸ§  Prompt Engineering (Under the Hood)

Every user question generates a rich, structured prompt like:

```text
You are a data analysis assistant. The following is a list of rows from a crime dataset...

ONLY use the data provided. Do NOT make up any data.

### Question:
What is the most stolen item in Abbotsford in 2025?

### Data:
<Row 1>
<Row 2>
...

### Instructions:
- Use rows that match the filters in the question.
- If nothing matches, say "No data found."
```

This ensures **grounded, explainable outputs** â€” ideal for high-trust domains like auditing, law enforcement, or finance.

---

## ğŸ“Œ Use Cases

* ğŸ•µï¸ Crime and safety data analysis
* ğŸ“ˆ Financial transaction review
* ğŸ§¾ Policy compliance checks
* ğŸ§  No-code internal BI assistants
* ğŸ“ Log + report analysis (GDPR, HIPAA, ISO, etc.)

---

## ğŸ” Why Offline?

* âœ… Privacy by default
* ğŸ’¸ Zero token/API costs
* ğŸ”„ Total control over data and model
* ğŸ” Fully explainable outputs with traceable context

---

## ğŸŒ Future Improvements

* [ ] ğŸ” Add support for PDFs, DOCX
* [ ] ğŸ“Š Integrate interactive charts with Plotly
* [ ] ğŸ§  Enable memory-aware follow-up Q\&A
* [ ] ğŸ’¾ Export answers to PDF/CSV
* [ ] ğŸ”„ Replace Gradio with Streamlit option

---

## ğŸ¤ Contributing

Got ideas? Want to adapt this for your industry? PRs are welcome!

```bash
# Fork + star â­
# Create a branch ğŸš€
# Submit a PR with improvements ğŸ’¡
```

---

## ğŸ™‹â€â™‚ï¸ Author & License

Built by [Abhc7](https://www.linkedin.com/in/abichaudhuri/)
MIT License Â© 2025

---

## ğŸŒŸ Acknowledgments

* HuggingFace Transformers + SentenceTransformers
* Facebook FAISS
* Gradio Team
* LM Studio / Ollama contributors
* All open-source AI pioneers ğŸ™Œ

---

## ğŸ”— Stay Connected

ğŸ’¬ [LinkedIn](https://www.linkedin.com/in/abichaudhuri/)
ğŸ“© Open to collaborations, demos, and talks!

---

> ğŸ§  Sometimes, the best AI isnâ€™t in the cloud â€” itâ€™s sitting quietly on your machine, waiting to be asked the right question.

```

